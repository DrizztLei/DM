* DONE 挖掘模式
  SCHEDULED: <2017-05-10 Wed>
  CLOSED: [2017-05-11 Thu 20:39]
  DEADLINE:<2017-05-11 Thu>
* 概念
*** 频繁项集 闭项集 关联规则
1) [X] 概念 [100%]
   1) [X] 支持度 support(A=>B) = P(A ∩ B)
   2) [X] 置信度 confidence(A=>B) = P(B | A)
   3) [X] 项集 项的集合
** 挖掘频繁模式方法
*** Aprioir FP-growth
1) [X] 概念与技术 [3/3]
   1) [X] Aprioir
      浪费空间与时间的做法
   2) [X] FP-growth
      构建类似字典树来整合空间与时间关系
   3) [X] 垂直数据格式挖掘频繁项集
** 挖掘闭模式和极大模式
1) [X] 概念与技术 [2/2]
   1) [X] 闭模式 [2/2]
      1) [X] 朴素方法
         频繁项集 的 完全集 , 删除是其他项集 的 真子集 , 并且 具有 相同 的 支持度
         这种 方法 开销 很大 .
      2) [X] 改进方法 [3/3]
         在 挖掘 过程 直接搜索 闭 频繁项集, 也就是 识别出 闭项集 然后 尽快对 搜索空间 减枝 .
         减枝 包括
         1) [X] 项合并
            X 的 每个 事物 包含 Y , 但是 不包含 Y 的 任何 真超集 . X U Y  成为 一个 闭频繁 项集 , 不必 搜索 包含 X 不 包含 Y 的 项集 .
         2) [X] 子项集 减枝
            X 是 Y 的 真子集 and support(X) == support(Y) 那么 X 与 X 在 集合 枚举树 中的所有后代 都不是 闭频繁项集 .
         3) [X] 项跳过
            深度有限的挖掘中, 每一层 都有 一个 与 头表和投影数据库相关连的前缀 X, 如果一个局部频繁项 p 不同的头表都有相同的 支持度 那么就可以从 高层的头表中裁剪掉.
   2) [X] 极大模式
      可以将 闭模式 的 挖掘技术 相应的 嵌套在 极大模式上
** 模式评估方法
1) [X] 从关联分析到相关分析 [5/5]
   1) [X] 提升度
      lift(A, B) = P(A ∪ B) / (P(A) * P(B))
      小于 1 负相关 大于1 正相关 1 是独立的
   2) [X] X^2 检验
      X^2 = sum((observe_value - expection_value)^2 / expection_value)
      然后根据自由度使用相依表
   3) [X] 全置信度
      all_conf(A, B) = sup(A union B) / max(support(A), support(B)) = min(P(A | B), P(B | A))
   4) [X] Kulczynski(Kulc) 度量
      Kulc(A, B) = (P(A | B) + P(B | A))/ 2
      可以看做两个置信度的平均值
   5) [X] 余弦度量
      cosine(A, B) = P(A ∪ B) / (P(A) * P(B)) ^ (1/2) = (P(A | B) * P(B | A)) ^ (1/2)
      可以看做 调和 提升度量
2) [X] 小结 [4/4]
   1) [X] 提升度 和 X^2 模式关联 分析 能力 有欠缺
   2) [X] 零事物 (null transaction)
      不包含 任何考察项集的事物
   3) [X] 不平衡比 IR(Imbalance Ratio)
      IR(A, B) = abs(sup(A) - sup(B)) / (sup(A) + sup(B) - sup(A ∪ B))
      如果 A, B 方向的蕴含 相同, 则IR(A, B) = 0
      IR 的值 越大越不平衡
   4) [X] 推荐
      Kluc 与 不平衡比 配合使用
** 高级 线路图表
   1) [X] 基础概念 [7/7]
      1) [X] 基于模式所涉及的抽象层
         buys(X, "computer") => buys(X, "printer")
         buys(X, "laptop_computer") => buys(X, "color_laser_printer")
         挖掘 规则集合 友 多层关联规则 组成
      2) [X] 基于规则 或 模式 涉及的 维数
         多维的例子:
         age(X, "20~30") intersect income(X, "52K~58K") => buys(X, "iPad")
      3) [X] 基于 规则 或者 模式 中 处理 值 的 类型
         是否出现就是一种 布尔型 的关联规则
         描述的如果是 量化的项 或者 属性 之间的 关联, 及时 量化的关联规则(quantitative association rule), 这种规则,项,属性量化值被换分为区间 .
      4) [X]  基于 挖掘选择性 模式的约束或者 标准
         模式 或者 规则 可以基于 约束 .
         比如 近似,压缩,近似匹配的 .
      5) [X] 基于 数据类型 或者 特征
      6) [X] 基于 应用 领域的特定语义
      7) [X] 基于 数据分析 的 使用方法
** 多层, 多维 空间 挖掘模式
    1) [X] 多层关联规则 [100%]
       1) [X] 对于所有层使用一致的最小支持度
       2) [X] 在较低的层使用递减的最小支持度
       3) [X] 使用基于项或者分组的最小支持度
          也叫 基于分组的支持度
          用户或这专家制定那些比较重要
    2) [X] 挖掘多维 关联 规则 [2/2]
       1) [X] 挖掘量化关联规则
          1) [X] 使用数据立方体
          2) [X] 使用聚类量化规则
          3) [X] 使用统计学理论发现异常行为
       2) [X] 挖掘 稀有模式 和 负模式
          1) [X] 稀有模式
          2) [X] 负模式
             // sup(X ∪ Y) < sup(X) * sup(Y) 那么 X Y 负相关, 且 X union Y 是 负相关模式 如果 sup(X ∪ Y) << sup(X) * sup(Y)
             // sup(X ∪ (~ B)) * sup((~ A) ∪ B) >> sup(X ∪ Y) * sup((~ X) union (~ Y))
             基于 Kulczynski
             if sup(X) >= min_sup, sup(Y) >= min_sup, (P(X | Y) + P(Y | X)) / 2 < threshold
    3) [X] 基于约束的 频繁挖掘模式[2/2]
       1) [X] 概念
          这些都可以使用高级挖掘技术查询语言实现
          1) [X] 知识类型
          2) [X] 数据约束
          3) [X] 维/层次约束
          4) [X] 兴趣度约束
          5) [X] 规则约束
             指定挖掘的 规则形式 或 条件
       2) [X] 处理 [100%]
          1) [X] 元规则 制导 挖掘
             P1(X, Y) intersect P2(X, W) => buys(X, "officessoftware")
             Pi 是 谓词变量
          2) [X] 模式产生 [2/2]
             1) [X] 模式空间 剪枝
                1) [X] 反单调
                   sum(I.price) <= $100
                   任何包括自己的超集无法满足约束
                2) [X] 单调的
                   sum(I.price) >= $100
                3) [X] 简洁的
                   可以 枚举 并且 确保 满足该 约束的 所有 集合
                4) [X] 可转变的
                   avg(I.price) <= $100
                   添加一些条件就可以转换
                5) [X] 不可转变的
                   sum(S) {>=, <=} v
             2) [X] 数据空间 剪枝
                策略是 减 对 其后 挖掘过程 中 可能 满足模式的产生 没有 贡献 的 数据片段
    4) [X] 挖掘 高维数据 和 巨型模式 [1/1]
       1) [X] 模式融合 [100%]
          融合少量的较短的频繁模式, 在模式 搜索空间 中跳跃.
          使用有限的宽度遍历, 只使用 侯选池中固定 个数的 模式作为 模式树 向下的开始节点
          这个是为了产生巨型模式的近似解
          1) [X] 核模式 (core pattern)
             模式α 项集β β ∈ a 称为 γ-核模式, 如果 |Dα| / |Dβ| >= γ, 0 < γ <= 1, |Dα| 是数据库 D 包含 α 的模式数, γ 为 核比率.
             d = max{|α| - |β| | β ∈ α, 并且β是α的γ-核模式}
             如果 d 是这些项的最大个数, 那么这些 项 可以从 α 删除, 结果模式依旧是 α的γ-核模式
          2) [X] 模式距离
             Dist(α, β) = 1 - (|Dα ∩ Dβ|) / (|Dα ∪ Dβ|) , 这个满足 三角不等式
             对于模式 α , Cα 为它所有 核模式的集合, 那么 Cα 被 度量空间的一个直径为r(γ)的球限定
             其中 r(γ) = 1 - 1 / (2 / γ - 1) , 也就是 给定一个 核模式 β∈Cα, 可以查询 识别当前池中所有的核模式.
          3) [X] 过程
             已经证明和检验过这个模式获得很好的近似解.
             1) 初始化
                短频繁模式的初始池. 是一个段长度的频繁模式的完全集.
             2) 迭代的模式融合
                制定K作为输入, 每次迭代中, 随机抽取K个种子, 对于每个种子, 找出直径为γ的球内的所有模式.    然后所有模式融合,形成超模式集.由于每个超模式的支集随着迭代搜索,所以停止.
    5) [X] 挖掘 压缩模式 和 近似 模式 [2/2]
       1) [X] 通过模式聚类
          1) [X] 闭模式的距离
             Pat_Dist(P1, P2) = 1 - |T(P1) ∩ T(P2)| / |T(P1) ∪ T(P2)|
             这个包含了模式的支持度信息
             T(P1) = {t1,t2,t3,t4,t5}, T{P2} = {t1,t2,t4,t5,t6}, Pat_Dist(P1, P2) = 1 - (4/6) = 1/3
             可以使用这个作为聚类来k-means聚类
          2) [X] P't覆盖
             如果O(P) ∈ O(P'), 并且 Pat_Dist(P, P') <= t, t -> threshold
             一个模式形成一个 t-簇, 使用t-簇,只需要计算每个模式与簇代表模式之间的距离.
             if and only if O(P)∈O(Pγ), 模式P被代表模式Pγ t- 覆盖的.
             所以通过支持度简化计算
             Pat_Dist(P, Pγ) = 1 - |T(P) ∩ T(Pγ)| / |T(P) ∩ T(Pγ)| = 1 - |T(Pγ)| / |T(P)|
             为了更简洁的压缩, 用于代表模式的支持读稍微小于 min_sup.
             t >= Pat_Dist(P, Pγ) = 1 - |T(Pγ)| / |T(P)| >= 1 - k/min_sup => k >= (1 - t) * min_sup
             这个是模式的最小支持度 , 计作 min_supγ.
             找到代表模式是NP的.
             给定 min_sup, 以及 t, 走到 代表模式的集合 R, 使得 对于每个频繁模式P(关于min_sup), 存在一个代表模式 P∈R(关于min_sup), 它覆盖P,并且|R|是最小的.

       2) [X] 提取感知冗余的 top-k 模式(redundancy-aware top-k patterns)
          + 感知冗余的top-k模式在显著性和冗余性间平衡.
            + 显著性度量 S
              S可以使用客观或者主观度量, tf-idf 支持度,置信度,相关度等.
              S(p|q) = S(p, q) - S(q)
              那么两个模式p,q冗余性 R(p, q) = S(p) + S(q) - S(p, q) => s(p|q) = S(p) - R(p,q)
              0 <= R(p, q) <= min(S(p), S(q))
              理想的R(p, q) 很难找到, 可以使用 模式间 距离 来近似 冗余度.
              发现感知冗余的top-k模式可以转换发现最大化边缘显著性的k-模式集问题.这个是信息检索研究透彻的问题.

    6) [X] 频繁模式的语义注解 [4/4]
       为了提供模式的语义解释
       1) [X] 语境单元
          数据库D的基本对象, 携带语义信息, 并且至少与一个频繁模式p一起至少一个出现在D的事物中.
          可以是 项, 模式, 或者事务.
       2) [X] 模式p的语境
          从数据库中来的甲醛的语境单元的集合.
          p的语境可以使用向量空间建模.
       3) [X] 基本任务
          1) [X] 选择语境单元, 设计单元强度权重,对频繁模式的语境建模
          2) [X] 为模式间语境, 事务, 设计相似性度量.
          3) [X] 对于给定的频繁模式, 提取最显著的语境指示符号,代表事务和语义相似模式,构建注解.
       4) [X] 过程
          1) 提取最重要的,非冗余的频繁模式.
             1) 可以使用模式压缩过的闭模式,或者使用Jaccard系数进行微聚类.然后从每个簇中选择代表的模式.
             2) 设定语境权重
                + 原则
                  + 模式p最好的语境是自己
                  + 两个模式一样强, 这权重一样
                + 实例
                  两个模式独立,那么都不能指示另一个的含义, p 的含义可以通过指示符推断.
                  互信息是多个可能的权重函数:
                  给定 两个频繁模式 pα pβ,
                  X = {0, 1}, Y = {0, 1},
                  0 代表不出现
                  I(X;Y) = ∑x∈X∑y∈Y P(x, y)log(P(x,y) / (P(x) * p(y)))
                  可以使用标准的拉普拉斯平滑来避免零概率.
                  P(1,1) = |Dα ∩ Dβ| / |D|
                  P(0,1) = (|Dβ| - |Dα ∩ Dβ|) / |D|
                  P(1,0) = (|Dα| - |Dα ∩ Dβ|) / |D|
                  P(0,0) = (|D| - |Dα ∪ Dβ|) / |D|
             3) 模式注解 [100%]
                1) [X] 提取最显著的语境指示符号
                   可以使用余弦相似性, 度量语境向量间的相似性, 按照权重排序, 提取多个最强的.
                2) [X] 提取代事务
                   把每个事务表示为一个语境向量, 根据模式p的语境相似性对事务排序.
                3) [X] 提取语境相似的模式
                   对每个频繁模式p, 根据语境模型与p的语境之间的相似性, 确定p的排序.
